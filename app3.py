import streamlit as st
from sentence_transformers import SentenceTransformer
import numpy as np
import faiss
import requests

# åŠ è½½å‘é‡æ–‡ä»¶
with np.load("embeddings.npz", allow_pickle=True) as data:
    documents = data["documents"].tolist()
    embeddings = data["embeddings"]

# åŠ è½½æ¨¡å‹
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

# å»ºç«‹å‘é‡ç´¢å¼•
index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(embeddings)

# API è®¾ç½®
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"
API_KEY = st.secrets["API_KEY"]  # å®‰å…¨å†™æ³•

# æ£€ç´¢å‡½æ•°
def retrieve_docs(question, top_k=3):
    q_embed = model.encode([question])
    D, I = index.search(q_embed, top_k)
    return [documents[i] for i in I[0]]

# API è°ƒç”¨å‡½æ•°
def call_deepseek_api(question, context):
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè¥å…»å­¦ä¸“å®¶ï¼Œè¯·ç»“åˆèµ„æ–™å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"},
            {"role": "user", "content": f"é—®é¢˜ï¼š{question}\nç›¸å…³æ–‡çŒ®ï¼š{context}"}
        ],
        "temperature": 0.7
    }
    response = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload)
    result = response.json()
    return result.get("choices", [{}])[0].get("message", {}).get("content", "æœªèƒ½ç”Ÿæˆå›ç­”ã€‚")

# Streamlit é¡µé¢
st.set_page_config(page_title="ğŸ¥— è¥å…»é—®ç­”æœºå™¨äºº", layout="centered")
st.title("ğŸ¥— è¥å…»çŸ¥è¯†é—®ç­”æœºå™¨äºº")
question = st.text_area("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜", placeholder="ä¾‹å¦‚ï¼šé’å°‘å¹´ä¸ºä»€ä¹ˆå®¹æ˜“è‚¥èƒ–ï¼Ÿ")

if st.button("æäº¤é—®é¢˜") and question.strip():
    with st.spinner("ç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™..."):
        relevant = retrieve_docs(question)
        context = "\n".join(relevant)
        answer = call_deepseek_api(question, context)
        st.markdown("### ğŸ¤– å›ç­”å¦‚ä¸‹ï¼š")
        st.write(answer)
